{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ifood-2019-fgvc6/train_labels.csv\n",
      "/kaggle/input/ifood-2019-fgvc6/test_set.zip\n",
      "/kaggle/input/ifood-2019-fgvc6/val_labels.csv\n",
      "/kaggle/input/ifood-2019-fgvc6/val_set.zip\n",
      "/kaggle/input/ifood-2019-fgvc6/sample_submission.csv\n",
      "/kaggle/input/ifood-2019-fgvc6/ifood2019_sample_submission.csv\n",
      "/kaggle/input/ifood-2019-fgvc6/train_set.zip\n",
      "/kaggle/input/ifood-2019-fgvc6/class_list.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzipping train_set.zip\n",
      "unzipping val_set.zip\n",
      "unzipping test_set.zip\n",
      "./\n",
      "./train_set\n",
      "./test_set\n",
      "./val_set\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"./train_set\"):\n",
    "    for file_name in ['train_set.zip', 'val_set.zip', 'test_set.zip']:\n",
    "        with ZipFile('../input/ifood-2019-fgvc6/' + file_name, 'r') as zipObj:\n",
    "            print(\"unzipping\", file_name)\n",
    "            zipObj.extractall('./')\n",
    "\n",
    "for dirname, _, _ in os.walk('./'):\n",
    "    print(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/ifood-2019-fgvc6/train_labels.csv')\n",
    "df_val   = pd.read_csv('../input/ifood-2019-fgvc6/val_labels.csv')\n",
    "df_test = pd.read_csv('../input/ifood-2019-fgvc6/sample_submission.csv')\n",
    "\n",
    "df_train['label'] = df_train['label'].astype(str)\n",
    "df_val['label'] = df_val['label'].astype(str)\n",
    "\n",
    "train_size = df_train.shape[0]\n",
    "val_size = df_val.shape[0]\n",
    "test_size = df_test.shape[0]\n",
    "num_classes = df_train['label'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, item in df_train.iterrows():\n",
    "    if not os.path.exists(\"./train_set/\" + item['label']):\n",
    "        os.mkdir(\"./train_set/\" + item['label'])\n",
    "    os.rename(\"./train_set/\"+item['img_name'], \"./train_set/\"+item['label']+\"/\"+item['img_name'])\n",
    "    \n",
    "for ind, item in df_val.iterrows():\n",
    "    if not os.path.exists(\"./val_set/\" + item['label']):\n",
    "        os.mkdir(\"./val_set/\" + item['label'])\n",
    "    os.rename(\"./val_set/\"+item['img_name'], \"./val_set/\"+item['label']+\"/\"+item['img_name'])\n",
    "\n",
    "os.mkdir(\"./test_set/0\")\n",
    "for ind, item in df_test.iterrows():\n",
    "    os.rename(\"./test_set/\"+item['img_name'], \"./test_set/0/\"+item['img_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "NUM_TRAIN = 10000\n",
    "NUM_VAL = 1000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "transform_train = T.Compose([\n",
    "    T.RandomResizedCrop(224),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "data_train = torchvision.datasets.ImageFolder(\n",
    "                root=\"./train_set\",\n",
    "                transform=transform_train\n",
    "            )\n",
    "# loader_train = DataLoader(data_train, batch_size=BATCH_SIZE, \n",
    "#                           sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "loader_train = DataLoader(data_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "data_val = torchvision.datasets.ImageFolder(\n",
    "                root=\"./val_set\",\n",
    "                transform=transform_test\n",
    "            )\n",
    "# loader_val = DataLoader(data_val, batch_size=BATCH_SIZE,\n",
    "#                        sampler=sampler.SubsetRandomSampler(range(NUM_VAL)))\n",
    "loader_val = DataLoader(data_val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "data_test = torchvision.datasets.ImageFolder(\n",
    "                root=\"./test_set\",\n",
    "                transform=transform_test\n",
    "            )\n",
    "loader_test = DataLoader(data_test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch data shape:  torch.Size([64, 3, 224, 224])\n",
      "batch label shape:  torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(loader_train))\n",
    "print(\"batch data shape: \", images.shape)\n",
    "print(\"batch label shape: \", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, epochs=1, print_every=100):\n",
    "    global best_acc\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        print('Epoch %d' % e)\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                train_acc = evaluate(loader_train, model, \"train\")\n",
    "                val_acc = evaluate(loader_val, model, \"val\")\n",
    "        print()\n",
    "        \n",
    "#         save_checkpoint({\n",
    "#                 'epoch': e + 1,\n",
    "#                 'state_dict': model.state_dict(),\n",
    "#                 'best_acc': best_acc,\n",
    "#             }, is_best)\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(loader, model, mode):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "#             _, preds = scores.max(1)\n",
    "            # top-3 prediction\n",
    "            _, preds = torch.topk(scores, k=3, dim=1)\n",
    "            num_correct += (preds == y.view(y.shape[0],1)).sum()\n",
    "            num_samples += preds.size(0)\n",
    "\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('%s: %d / %d correct (%.2f)' % (mode, num_correct, num_samples, 100 * acc))\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(loader, model):\n",
    "    model.eval()\n",
    "    y_pred = torch.tensor([], dtype=torch.long, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "#             _, preds = scores.max(1)\n",
    "            # top-3 prediction\n",
    "            _, preds = torch.topk(scores, k=3, dim=1)\n",
    "            y_pred = torch.cat((y_pred, preds), 0)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 32, (5, 5), padding=2),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 32, (5, 5), padding=2),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Dropout(0.25),\n",
    "    \n",
    "    nn.Conv2d(32, 64, (3, 3), padding=1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 64, (3, 3), padding=1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Dropout(0.25),\n",
    "    \n",
    "    nn.Flatten(),\n",
    "    nn.Linear(64 * 56 * 56, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, num_classes),\n",
    ")\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "#                      momentum=0.9, nesterov=True)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Iteration 0, loss = 5.5800\n",
      "train: 1451 / 118475 correct (1.22)\n",
      "val: 132 / 11994 correct (1.10)\n",
      "Iteration 100, loss = 5.5933\n",
      "train: 3171 / 118475 correct (2.68)\n",
      "val: 267 / 11994 correct (2.23)\n",
      "Iteration 200, loss = 5.3725\n",
      "train: 6658 / 118475 correct (5.62)\n",
      "val: 694 / 11994 correct (5.79)\n",
      "Iteration 300, loss = 5.4536\n",
      "train: 7734 / 118475 correct (6.53)\n",
      "val: 819 / 11994 correct (6.83)\n",
      "Iteration 400, loss = 5.1450\n",
      "train: 8990 / 118475 correct (7.59)\n",
      "val: 964 / 11994 correct (8.04)\n",
      "Iteration 500, loss = 5.4150\n",
      "train: 9807 / 118475 correct (8.28)\n",
      "val: 1105 / 11994 correct (9.21)\n",
      "Iteration 600, loss = 5.1616\n",
      "train: 10658 / 118475 correct (9.00)\n",
      "val: 1238 / 11994 correct (10.32)\n",
      "Iteration 700, loss = 5.1332\n",
      "train: 11612 / 118475 correct (9.80)\n",
      "val: 1343 / 11994 correct (11.20)\n",
      "Iteration 800, loss = 5.1191\n",
      "train: 11997 / 118475 correct (10.13)\n",
      "val: 1409 / 11994 correct (11.75)\n",
      "Iteration 900, loss = 5.0143\n",
      "train: 12599 / 118475 correct (10.63)\n",
      "val: 1591 / 11994 correct (13.26)\n",
      "Iteration 1000, loss = 5.0582\n",
      "train: 13765 / 118475 correct (11.62)\n",
      "val: 1628 / 11994 correct (13.57)\n",
      "Iteration 1100, loss = 5.2578\n",
      "train: 13847 / 118475 correct (11.69)\n",
      "val: 1596 / 11994 correct (13.31)\n",
      "Iteration 1200, loss = 4.9164\n",
      "train: 14800 / 118475 correct (12.49)\n",
      "val: 1721 / 11994 correct (14.35)\n",
      "Iteration 1300, loss = 4.6624\n",
      "train: 15514 / 118475 correct (13.09)\n",
      "val: 1944 / 11994 correct (16.21)\n",
      "Iteration 1400, loss = 4.7845\n",
      "train: 15726 / 118475 correct (13.27)\n",
      "val: 1756 / 11994 correct (14.64)\n",
      "Iteration 1500, loss = 4.9451\n",
      "train: 16594 / 118475 correct (14.01)\n",
      "val: 2077 / 11994 correct (17.32)\n",
      "Iteration 1600, loss = 4.9471\n",
      "train: 16644 / 118475 correct (14.05)\n",
      "val: 1986 / 11994 correct (16.56)\n",
      "Iteration 1700, loss = 4.7113\n",
      "train: 16984 / 118475 correct (14.34)\n",
      "val: 2011 / 11994 correct (16.77)\n",
      "Iteration 1800, loss = 4.7975\n",
      "train: 16995 / 118475 correct (14.34)\n",
      "val: 1948 / 11994 correct (16.24)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "train(model, optimizer, epochs=1, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(loader_test, model)\n",
    "df_test['label'] = [' '.join(item) for item in y_pred.cpu().numpy().astype(str)]\n",
    "df_test.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in [\"./train_set\", \"./val_set\", \"./test_set\"]:\n",
    "    shutil.rmtree(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
