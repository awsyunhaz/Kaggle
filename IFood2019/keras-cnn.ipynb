{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "bb5a88f3-ef0a-4db3-9eb7-8c8e02bf8ccc",
    "_uuid": "5852328c-95db-4ace-8d14-5a34b407823d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ifood-2019-fgvc6/sample_submission.csv\n",
      "/kaggle/input/ifood-2019-fgvc6/class_list.txt\n",
      "/kaggle/input/ifood-2019-fgvc6/train_set.zip\n",
      "/kaggle/input/ifood-2019-fgvc6/train_labels.csv\n",
      "/kaggle/input/ifood-2019-fgvc6/ifood2019_sample_submission.csv\n",
      "/kaggle/input/ifood-2019-fgvc6/val_set.zip\n",
      "/kaggle/input/ifood-2019-fgvc6/test_set.zip\n",
      "/kaggle/input/ifood-2019-fgvc6/val_labels.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "cf587b03-9a46-4ed4-93ed-126b27c0fa15",
    "_uuid": "4dff6dd9-2037-481d-90f5-41c7b6a2663e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzipping train_set.zip\n",
      "unzipping val_set.zip\n",
      "unzipping test_set.zip\n",
      "./\n",
      "./test_set\n",
      "./train_set\n",
      "./val_set\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"./train_set\"):\n",
    "    for file_name in ['train_set.zip', 'val_set.zip', 'test_set.zip']:\n",
    "        with ZipFile('../input/ifood-2019-fgvc6/' + file_name, 'r') as zipObj:\n",
    "            print(\"unzipping\", file_name)\n",
    "            zipObj.extractall('./')\n",
    "\n",
    "for dirname, _, _ in os.walk('./'):\n",
    "    print(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b3b34de0-301f-4758-baf9-86ee9dd00bad",
    "_uuid": "f097189c-baa4-41a9-91e2-60af2eb1bf6c"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/ifood-2019-fgvc6/train_labels.csv')\n",
    "df_val   = pd.read_csv('../input/ifood-2019-fgvc6/val_labels.csv')\n",
    "df_test = pd.read_csv('../input/ifood-2019-fgvc6/sample_submission.csv')\n",
    "\n",
    "df_train['label'] = df_train['label'].astype(str)\n",
    "df_val['label'] = df_val['label'].astype(str)\n",
    "\n",
    "train_size = df_train.shape[0]\n",
    "val_size = df_val.shape[0]\n",
    "test_size = df_test.shape[0]\n",
    "num_classes = df_train['label'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "cea3e86f-5e11-4430-b2b3-4ea2043b7676",
    "_uuid": "6ab1c755-9d02-4cd2-ade2-4008b26c6cad"
   },
   "outputs": [],
   "source": [
    "# from skimage import io\n",
    "# from skimage.transform import resize\n",
    "\n",
    "# X_train = np.zeros((10000, 256, 256, 3), dtype=np.uint8)\n",
    "# X_val = np.zeros((1000, 256, 256, 3), dtype=np.uint8)\n",
    "\n",
    "# print(\"load training images...\")\n",
    "# for row, file in zip(range(10000), df_train['img_name']):\n",
    "#     if (row % 1000 == 0):\n",
    "#         print(row)\n",
    "#     img = io.imread(\"./data/train_set/\" + file)\n",
    "#     X_train[row] = resize(img, (256, 256))\n",
    "\n",
    "# print(\"load validation images...\")\n",
    "# for row, file in zip(range(1000), df_val['img_name']):\n",
    "#     img = io.imread(\"./data/val_set/\" + file)\n",
    "#     X_val[row] = resize(img, (256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "ba1b3ee5-32cc-4068-9cef-e4f6a92857bd",
    "_uuid": "150a5d2a-4c67-4eb7-a974-0dfc079b8783"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# kernel_size = 3\n",
    "# filters     = 16\n",
    "# latent_dim  = 128\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b2392b10-5f88-4cd1-a98f-44fa2be53254",
    "_uuid": "a010e74c-97af-4a06-a02e-20a856108881"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 118475 validated image filenames belonging to 251 classes.\n",
      "Found 11994 validated image filenames belonging to 251 classes.\n",
      "Found 28377 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "batch_size  = 64\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    df_train,\n",
    "    x_col='img_name',\n",
    "    y_col='label',    \n",
    "    class_mode='categorical',\n",
    "    directory='./train_set/',\n",
    "    shuffle=True,\n",
    "#     color_mode='grayscale',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_generator = train_datagen.flow_from_dataframe(\n",
    "    df_val,\n",
    "    x_col='img_name',\n",
    "    y_col='label',    \n",
    "    class_mode='categorical',\n",
    "    directory='./val_set/',\n",
    "    shuffle=False,\n",
    "#     color_mode='grayscale',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    df_test,\n",
    "    x_col='img_name',\n",
    "    directory='./test_set/',\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "#     color_mode='grayscale',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPU Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import Dense, Activation, Flatten\n",
    "# from keras.models import Sequential\n",
    "# from keras.optimizers import RMSprop\n",
    "# import tensorflow as tf\n",
    "\n",
    "# # detect and init the TPU\n",
    "# tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "# tf.config.experimental_connect_to_cluster(tpu)\n",
    "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "\n",
    "# # instantiate a distribution strategy\n",
    "# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "# # instantiating the model in the strategy scope creates the model on the TPU\n",
    "# with tpu_strategy.scope():\n",
    "# #     model = tf.keras.Sequential( … ) # define your model normally\n",
    "# #     model.compile( … )\n",
    "#     model = Sequential()\n",
    "#     model.add(Flatten(input_shape=input_shape))\n",
    "#     model.add(Dense(num_classes))\n",
    "#     model.add(Activation('softmax'))\n",
    "\n",
    "#     # initiate RMSprop optimizer\n",
    "#     opt = RMSprop(learning_rate=0.001, decay=1e-6)\n",
    "\n",
    "#     # Let's train the model using RMSprop\n",
    "#     model.compile(loss='categorical_crossentropy',\n",
    "#                   optimizer=opt,\n",
    "#                   metrics=['accuracy'])\n",
    "\n",
    "# model.fit_generator(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=train_size//batch_size,\n",
    "#     epochs=1,\n",
    "#     validation_data=val_generator,\n",
    "#     validation_steps=val_size//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "77bc2f92-e724-4d89-bc60-85c0a556b99c",
    "_uuid": "93a31f6d-0323-4231-97ca-f2ea18c8ab12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# !pip uninstall tensorflow tensorflow-gpu keras --y\n",
    "# !pip install tensorflow-gpu keras\n",
    "\n",
    "# from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "# import keras.backend as K\n",
    "\n",
    "# print(device_lib.list_local_devices())\n",
    "print(tf.config.experimental.list_physical_devices('GPU'))\n",
    "print(tf.test.is_gpu_available())\n",
    "# print(K.backend())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "c3065212-306a-40ce-ab85-15e40d417314",
    "_uuid": "eb2458b6-f22b-4a02-8ed2-1cb4ea5e9b64"
   },
   "outputs": [],
   "source": [
    "\n",
    "# from keras.layers import Dense, Activation, Flatten\n",
    "# from keras.models import Sequential\n",
    "# from keras.optimizers import RMSprop\n",
    "\n",
    "# # network parameters\n",
    "# input_shape = (256, 256, 3)\n",
    "# batch_size  = 64\n",
    "# epochs      = 10\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Flatten(input_shape=input_shape))\n",
    "# model.add(Dense(num_classes))\n",
    "# model.add(Activation('softmax'))\n",
    "\n",
    "# # initiate RMSprop optimizer\n",
    "# opt = RMSprop(learning_rate=0.001, decay=1e-6)\n",
    "\n",
    "# # Let's train the model using RMSprop\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=opt,\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.fit_generator(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=train_size//batch_size,\n",
    "#     epochs=1,\n",
    "#     validation_data=val_generator,\n",
    "#     validation_steps=val_size//batch_size,\n",
    "#     use_multiprocessing=True,\n",
    "#     workers=4,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 256, 256, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 254, 254, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 254, 254, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 127, 127, 64)      18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 127, 127, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 125, 125, 64)      36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 125, 125, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 246016)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               125960704 \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 251)               128763    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 251)               0         \n",
      "=================================================================\n",
      "Total params: 126,155,035\n",
      "Trainable params: 126,155,035\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# network parameters\n",
    "input_shape = (256, 256, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1852/1852 [==============================] - 25457s 14s/step - loss: 5.3515 - accuracy: 0.0129 - val_loss: 5.0048 - val_accuracy: 0.0328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fd5f42f7e10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs      = 1\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = RMSprop(learning_rate=0.001)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_files = test_generator.filenames\n",
    "# test_size = len(test_files)\n",
    "y_predict = model.predict_generator(\n",
    "    test_generator, \n",
    "    steps=test_size)\n",
    "# df_test['label'] = y_predict.argmax(axis=1)\n",
    "y_predict = y_predict.argsort(axis=1)[:, -3:]\n",
    "df_test['label'] = [' '.join(item) for item in y_predict.astype(str)]\n",
    "\n",
    "df_test.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "for path in [\"./train_set\", \"./val_set\", \"./test_set\"]:\n",
    "    shutil.rmtree(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
