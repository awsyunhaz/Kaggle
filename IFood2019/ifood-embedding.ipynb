{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ifood-2019-fgvc6/test_set.zip\n",
      "/kaggle/input/ifood-2019-fgvc6/train_labels.csv\n",
      "/kaggle/input/ifood-2019-fgvc6/ifood2019_sample_submission.csv\n",
      "/kaggle/input/ifood-2019-fgvc6/val_set.zip\n",
      "/kaggle/input/ifood-2019-fgvc6/train_set.zip\n",
      "/kaggle/input/ifood-2019-fgvc6/val_labels.csv\n",
      "/kaggle/input/ifood-2019-fgvc6/sample_submission.csv\n",
      "/kaggle/input/ifood-2019-fgvc6/class_list.txt\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzipping train_set.zip\n",
      "unzipping val_set.zip\n",
      "unzipping test_set.zip\n",
      "./\n",
      "./val_set\n",
      "./test_set\n",
      "./train_set\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"./train_set\"):\n",
    "    for file_name in ['train_set.zip', 'val_set.zip', 'test_set.zip']:\n",
    "        with ZipFile('../input/ifood-2019-fgvc6/' + file_name, 'r') as zipObj:\n",
    "            print(\"unzipping\", file_name)\n",
    "            zipObj.extractall('./')\n",
    "\n",
    "for dirname, _, _ in os.walk('./'):\n",
    "    print(dirname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/ifood-2019-fgvc6/train_labels.csv')\n",
    "df_val   = pd.read_csv('../input/ifood-2019-fgvc6/val_labels.csv')\n",
    "df_test = pd.read_csv('../input/ifood-2019-fgvc6/sample_submission.csv')\n",
    "\n",
    "df_train['label'] = df_train['label'].astype(str)\n",
    "df_val['label'] = df_val['label'].astype(str)\n",
    "\n",
    "train_size = df_train.shape[0]\n",
    "val_size = df_val.shape[0]\n",
    "test_size = df_test.shape[0]\n",
    "num_classes = df_train['label'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    fill_mode='nearest',\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 118475 validated image filenames.\n",
      "Found 11994 validated image filenames.\n",
      "Found 28377 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "\n",
    "batch_size  = 64\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    df_train,\n",
    "    x_col='img_name',\n",
    "    y_col='label',    \n",
    "    class_mode='input',\n",
    "    directory='./train_set/',\n",
    "    shuffle=True,\n",
    "#     color_mode='grayscale',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_generator = train_datagen.flow_from_dataframe(\n",
    "    df_val,\n",
    "    x_col='img_name',\n",
    "    y_col='label',    \n",
    "    class_mode='input',\n",
    "    directory='./val_set/',\n",
    "    shuffle=False,\n",
    "#     color_mode='grayscale',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    df_test,\n",
    "    x_col='img_name',\n",
    "    directory='./test_set/',\n",
    "    class_mode='input',\n",
    "    shuffle=False,\n",
    "#     color_mode='grayscale',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 256, 256, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 128, 16)      4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 8)         584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 8)         584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 64, 64, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 64, 64, 16)        1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 128, 128, 32)      4640      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 256, 256, 3)       867       \n",
      "=================================================================\n",
      "Total params: 15,107\n",
      "Trainable params: 15,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# network parameters\n",
    "input_shape = (256, 256, 3)\n",
    "\n",
    "# # detect and init the TPU\n",
    "# tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "# tf.config.experimental_connect_to_cluster(tpu)\n",
    "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "\n",
    "# # instantiate a distribution strategy\n",
    "# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "# # instantiating the model in the strategy scope creates the model on the TPU\n",
    "# with tpu_strategy.scope():\n",
    "# #     model = tf.keras.Sequential( … ) # define your model normally\n",
    "# #     model.compile( … )\n",
    "#     # encoder\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "\n",
    "# decoder\n",
    "# at this point the representation is (16, 16, 8) i.e. 512-dimensional\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(3, (3, 3), activation='sigmoid', padding='same'))\n",
    "\n",
    "model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "157/156 [==============================] - 518s 3s/step - loss: 0.6200 - accuracy: 0.0326 - val_loss: 0.5607 - val_accuracy: 0.0290\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.56067, saving model to autoencoder.hdf5\n",
      "Epoch 2/50\n",
      "157/156 [==============================] - 502s 3s/step - loss: 0.5627 - accuracy: 0.0370 - val_loss: 0.5573 - val_accuracy: 0.0293\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.56067 to 0.55730, saving model to autoencoder.hdf5\n",
      "Epoch 3/50\n",
      "157/156 [==============================] - 502s 3s/step - loss: 0.5504 - accuracy: 0.0384 - val_loss: 0.5406 - val_accuracy: 0.0300\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.55730 to 0.54065, saving model to autoencoder.hdf5\n",
      "Epoch 4/50\n",
      "157/156 [==============================] - 503s 3s/step - loss: 0.5463 - accuracy: 0.0366 - val_loss: 0.5488 - val_accuracy: 0.0296\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.54065\n",
      "Epoch 5/50\n",
      "157/156 [==============================] - 502s 3s/step - loss: 0.5400 - accuracy: 0.0377 - val_loss: 0.5459 - val_accuracy: 0.0296\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.54065\n",
      "Epoch 6/50\n",
      "157/156 [==============================] - 507s 3s/step - loss: 0.5331 - accuracy: 0.0392 - val_loss: 0.5342 - val_accuracy: 0.0294\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.54065 to 0.53416, saving model to autoencoder.hdf5\n",
      "Epoch 7/50\n",
      "157/156 [==============================] - 510s 3s/step - loss: 0.5325 - accuracy: 0.0377 - val_loss: 0.5265 - val_accuracy: 0.0298\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.53416 to 0.52648, saving model to autoencoder.hdf5\n",
      "Epoch 8/50\n",
      "157/156 [==============================] - 509s 3s/step - loss: 0.5304 - accuracy: 0.0377 - val_loss: 0.5361 - val_accuracy: 0.0295\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.52648\n",
      "Epoch 9/50\n",
      "157/156 [==============================] - 512s 3s/step - loss: 0.5291 - accuracy: 0.0375 - val_loss: 0.5319 - val_accuracy: 0.0296\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.52648\n",
      "Epoch 10/50\n",
      "157/156 [==============================] - 514s 3s/step - loss: 0.5280 - accuracy: 0.0385 - val_loss: 0.5315 - val_accuracy: 0.0292\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.52648\n",
      "Epoch 11/50\n",
      "157/156 [==============================] - 507s 3s/step - loss: 0.5264 - accuracy: 0.0369 - val_loss: 0.5352 - val_accuracy: 0.0298\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.52648\n",
      "Epoch 12/50\n",
      "157/156 [==============================] - 512s 3s/step - loss: 0.5248 - accuracy: 0.0385 - val_loss: 0.5297 - val_accuracy: 0.0297\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.52648\n",
      "Epoch 13/50\n",
      "157/156 [==============================] - 512s 3s/step - loss: 0.5248 - accuracy: 0.0380 - val_loss: 0.5347 - val_accuracy: 0.0297\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.52648\n",
      "Epoch 14/50\n",
      "157/156 [==============================] - 506s 3s/step - loss: 0.5234 - accuracy: 0.0386 - val_loss: 0.5268 - val_accuracy: 0.0294\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.52648\n",
      "Epoch 15/50\n",
      "157/156 [==============================] - 509s 3s/step - loss: 0.5235 - accuracy: 0.0387 - val_loss: 0.5465 - val_accuracy: 0.0295\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.52648\n",
      "Epoch 16/50\n",
      "157/156 [==============================] - 512s 3s/step - loss: 0.5227 - accuracy: 0.0376 - val_loss: 0.5194 - val_accuracy: 0.0295\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.52648 to 0.51938, saving model to autoencoder.hdf5\n",
      "Epoch 17/50\n",
      "157/156 [==============================] - 510s 3s/step - loss: 0.5204 - accuracy: 0.0383 - val_loss: 0.5205 - val_accuracy: 0.0298\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.51938\n",
      "Epoch 18/50\n",
      "157/156 [==============================] - 517s 3s/step - loss: 0.5223 - accuracy: 0.0373 - val_loss: 0.5185 - val_accuracy: 0.0296\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.51938 to 0.51849, saving model to autoencoder.hdf5\n",
      "Epoch 19/50\n",
      "157/156 [==============================] - 525s 3s/step - loss: 0.5202 - accuracy: 0.0400 - val_loss: 0.5303 - val_accuracy: 0.0298\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.51849\n",
      "Epoch 20/50\n",
      "157/156 [==============================] - 523s 3s/step - loss: 0.5203 - accuracy: 0.0360 - val_loss: 0.5145 - val_accuracy: 0.0297\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.51849 to 0.51453, saving model to autoencoder.hdf5\n",
      "Epoch 21/50\n",
      "157/156 [==============================] - 528s 3s/step - loss: 0.5194 - accuracy: 0.0381 - val_loss: 0.5168 - val_accuracy: 0.0296\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.51453\n",
      "Epoch 22/50\n",
      "157/156 [==============================] - 525s 3s/step - loss: 0.5186 - accuracy: 0.0387 - val_loss: 0.5171 - val_accuracy: 0.0297\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.51453\n",
      "Epoch 23/50\n",
      "157/156 [==============================] - 526s 3s/step - loss: 0.5178 - accuracy: 0.0367 - val_loss: 0.5193 - val_accuracy: 0.0295\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.51453\n",
      "Epoch 24/50\n",
      "157/156 [==============================] - 529s 3s/step - loss: 0.5180 - accuracy: 0.0359 - val_loss: 0.5239 - val_accuracy: 0.0299\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.51453\n",
      "Epoch 25/50\n",
      "157/156 [==============================] - 522s 3s/step - loss: 0.5166 - accuracy: 0.0392 - val_loss: 0.5144 - val_accuracy: 0.0298\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.51453 to 0.51443, saving model to autoencoder.hdf5\n",
      "Epoch 26/50\n",
      "157/156 [==============================] - 540s 3s/step - loss: 0.5170 - accuracy: 0.0371 - val_loss: 0.5249 - val_accuracy: 0.0297\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.51443\n",
      "Epoch 27/50\n",
      "157/156 [==============================] - 502s 3s/step - loss: 0.5158 - accuracy: 0.0384 - val_loss: 0.5224 - val_accuracy: 0.0296\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.51443\n",
      "Epoch 28/50\n",
      "157/156 [==============================] - 500s 3s/step - loss: 0.5172 - accuracy: 0.0351 - val_loss: 0.5176 - val_accuracy: 0.0296\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.51443\n",
      "Epoch 29/50\n",
      "157/156 [==============================] - 503s 3s/step - loss: 0.5170 - accuracy: 0.0370 - val_loss: 0.5160 - val_accuracy: 0.0298\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.51443\n",
      "Epoch 30/50\n",
      "157/156 [==============================] - 500s 3s/step - loss: 0.5148 - accuracy: 0.0374 - val_loss: 0.5074 - val_accuracy: 0.0298\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.51443 to 0.50741, saving model to autoencoder.hdf5\n",
      "Epoch 31/50\n",
      "157/156 [==============================] - 500s 3s/step - loss: 0.5149 - accuracy: 0.0390 - val_loss: 0.5149 - val_accuracy: 0.0296\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.50741\n",
      "Epoch 32/50\n",
      "157/156 [==============================] - 500s 3s/step - loss: 0.5153 - accuracy: 0.0385 - val_loss: 0.5071 - val_accuracy: 0.0298\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.50741 to 0.50706, saving model to autoencoder.hdf5\n",
      "Epoch 33/50\n",
      "157/156 [==============================] - 501s 3s/step - loss: 0.5139 - accuracy: 0.0389 - val_loss: 0.5133 - val_accuracy: 0.0295\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.50706\n",
      "Epoch 34/50\n",
      "157/156 [==============================] - 500s 3s/step - loss: 0.5152 - accuracy: 0.0384 - val_loss: 0.5211 - val_accuracy: 0.0298\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.50706\n",
      "Epoch 35/50\n",
      "157/156 [==============================] - 505s 3s/step - loss: 0.5128 - accuracy: 0.0386 - val_loss: 0.5133 - val_accuracy: 0.0296\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.50706\n",
      "Epoch 36/50\n",
      "157/156 [==============================] - 534s 3s/step - loss: 0.5152 - accuracy: 0.0362 - val_loss: 0.5244 - val_accuracy: 0.0296\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.50706\n",
      "Epoch 37/50\n",
      "157/156 [==============================] - 524s 3s/step - loss: 0.5130 - accuracy: 0.0384 - val_loss: 0.5271 - val_accuracy: 0.0297\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.50706\n",
      "Epoch 38/50\n",
      "157/156 [==============================] - 512s 3s/step - loss: 0.5118 - accuracy: 0.0400 - val_loss: 0.5176 - val_accuracy: 0.0299\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.50706\n",
      "Epoch 39/50\n",
      "157/156 [==============================] - 513s 3s/step - loss: 0.5129 - accuracy: 0.0359 - val_loss: 0.5195 - val_accuracy: 0.0296\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.50706\n",
      "Epoch 40/50\n",
      "157/156 [==============================] - 520s 3s/step - loss: 0.5123 - accuracy: 0.0376 - val_loss: 0.5158 - val_accuracy: 0.0296\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.50706\n",
      "Epoch 41/50\n",
      "157/156 [==============================] - 520s 3s/step - loss: 0.5131 - accuracy: 0.0379 - val_loss: 0.5116 - val_accuracy: 0.0295\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.50706\n",
      "Epoch 42/50\n",
      "157/156 [==============================] - 522s 3s/step - loss: 0.5117 - accuracy: 0.0386 - val_loss: 0.5104 - val_accuracy: 0.0297\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.50706\n",
      "Epoch 43/50\n",
      "157/156 [==============================] - 513s 3s/step - loss: 0.5128 - accuracy: 0.0369 - val_loss: 0.5156 - val_accuracy: 0.0297\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.50706\n",
      "Epoch 44/50\n",
      "157/156 [==============================] - 516s 3s/step - loss: 0.5105 - accuracy: 0.0387 - val_loss: 0.5223 - val_accuracy: 0.0297\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.50706\n",
      "Epoch 45/50\n",
      "157/156 [==============================] - 518s 3s/step - loss: 0.5113 - accuracy: 0.0386 - val_loss: 0.5126 - val_accuracy: 0.0299\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.50706\n",
      "Epoch 46/50\n",
      "157/156 [==============================] - 515s 3s/step - loss: 0.5105 - accuracy: 0.0388 - val_loss: 0.5063 - val_accuracy: 0.0297\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.50706 to 0.50626, saving model to autoencoder.hdf5\n",
      "Epoch 47/50\n",
      "157/156 [==============================] - 513s 3s/step - loss: 0.5107 - accuracy: 0.0372 - val_loss: 0.5130 - val_accuracy: 0.0299\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.50626\n",
      "Epoch 48/50\n",
      "157/156 [==============================] - 504s 3s/step - loss: 0.5114 - accuracy: 0.0387 - val_loss: 0.5075 - val_accuracy: 0.0300\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.50626\n",
      "Epoch 49/50\n",
      "157/156 [==============================] - 509s 3s/step - loss: 0.5098 - accuracy: 0.0385 - val_loss: 0.5168 - val_accuracy: 0.0297\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.50626\n",
      "Epoch 50/50\n",
      "157/156 [==============================] - 509s 3s/step - loss: 0.5107 - accuracy: 0.0380 - val_loss: 0.5079 - val_accuracy: 0.0298\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.50626\n"
     ]
    }
   ],
   "source": [
    "# Save best model\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "filepath       = \"autoencoder.hdf5\"\n",
    "checkpoint     = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "epochs      = 50\n",
    "num_samples = 10000\n",
    "hist = model.fit_generator(train_generator,\n",
    "                            steps_per_epoch=num_samples/batch_size,\n",
    "                            validation_data=val_generator,\n",
    "                            validation_steps=len(val_generator),\n",
    "                            callbacks=callbacks_list,                                 \n",
    "                            epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "for path in [\"./train_set\", \"./val_set\", \"./test_set\"]:\n",
    "    shutil.rmtree(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
